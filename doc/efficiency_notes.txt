Le's front-end code parallelized pretty well. Linear increase in efficiency with cores. Would benefit greatly from DS compute node.

Cassy's DPC code was already fairly well optomized, but is still very slow. I tried some methods to reduce data overhead, but
these did not improve performace. Then realized infnorm was not vectorized! Yay. Reduced compute time 1/3 to 3-fold depeding on 
LSAP complexity.

Tried lpSolve library, but it has a ton of overhead to solution and was even slower.

My lapotp sucks at taking advantage of parrallelization. Also runs out of memory if I try to use n-1 threads. Basically shit.

Even so, achieved an average of 2.4-fold decrease in compute time between code improvements and parallelization (on DPC).

TODO: Restructure functions



# On AWS:
Apparaently TDA has bas Linux install after v1.4.1 ? Stack overflow from 1 month ago:
https://stackoverflow.com/questions/45646946/error-when-installing-tda-package-on-r-recipe-for-target-diag-o-failed
No ability to submit issues on github???


210 sec for 1 on c5d.18xlarge
244 sec for 10
358 sec for 50

Worst case on this machine:
400 * ceiling(n/71)

So, ~1200 sec for n=150, which is 20 minutes.

Round up to 30 min, and this would cost ~2$ at most. To benchmark 20 values of c, would cost $40


More Likely, $25 and 6 hours



Le:
Be careful about Classify vs classify. Caused a lot of problems later on! Scoped sunctions, etc. rather than repeating. So
much repetition with small changes to things like caps makes it easy to mess up.





DPC test for c without resolving if not neccessary!

Memoising these big matrices seems to be too much, but we can still stop the for-loop when cost[i]==cost[i-1], i.e.
min(c,max(r)) is max(r) in all cases...



15 values of c       1 c
1069.28              331.04

so, 3.23x longer to test 15 values of c.

Now, maybe we can do all of that for <$5!

For 15 values of c dpc0 and dpc1 on 71 threads:
1892.77 for r0 and 9.4 for r1

That's 32 minutes! So, I did this for 2$.


#TODO: MAKE SURE THAT RBIND IS ON CORRECT END OF THOSE MATRICES!!!!!




What is 10-fold crossvalidation really?


Should we start a lab repo with best practices?




This is basically Max-Likelihood approach, but what about a statistical classifier?


