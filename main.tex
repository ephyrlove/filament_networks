\documentclass[10pt]{article}

\usepackage{fullpage} % Package to use full page
\usepackage{parskip} % Package to tweak paragraph skipping
\usepackage{tikz} % Package for drawing
\usepackage{amsmath}
\usepackage{hyperref}
\usepackage{graphics,multirow,cases,algorithm,algpseudocode}
\usepackage{booktabs,color,comment}
\usepackage[english]{babel}
\usepackage{amsmath,amsthm,amssymb,verbatim,bbm}
%\usepackage[framed,numbered,autolinebreaks,useliterate]{mcode}
\usepackage{url}
\usepackage{nomencl}
\usepackage{enumitem}
\usepackage{siunitx}

\usepackage[normalem]{ulem}

\newcommand*{\bbar}[1]{\bar{\bar{#1}}}

\newcommand{\R}{{\mathcal{R}}}
\newcommand{\T}{{\mathcal{T}}}
\newcommand{\D}{{\mathcal{D}}}
\newcommand{\F}{{\mathcal{F}}}
\renewcommand{\S}{{\mathcal{S}}}
\newcommand{\spb}{{\smallskip}}
\newcommand{\mpb}{{\medskip}}
\newcommand{\bpb}{{\bigskip}}
\newcommand{\IN}{{\mathbb{N}}}
\newcommand{\IM}{{\mathbb{M}}}
\newcommand{\IZ}{{\mathbb{Z}}}
\newcommand{\IR}{{\mathbb{R}}}
\newcommand{\IE}{{\mathbb{E}}}
\newcommand{\IP}{{\mathbb{P}}}
\newcommand{\IC}{{\mathbb{C}}}
\newcommand{\mO}{{\mathcal{O}}}
%\newcommand{\IR}{{\mathbb{R}}}
%\newcommand{\IC}{{\mathbb{C}}}
%\newcommand{\IN}{{\mathbb{N}}}
%\newcommand{\IE}{{\mathbb{E}}}
%\newcommand{\IP}{{\mathbb{P}}}
\newcommand{\mF}{{\mathcal{F}}}
\newcommand{\mE}{{\mathcal{E}}}
\newcommand{\tT}{\intercal}
\newcommand{\mT}{{\mathcal{T}}}
\newcommand{\mconv}{{\mathrm{conv}}}
\newcommand{\mC}{{\mathcal{C}}_{2 \pi}}
\newcommand{\IX}{{\mathbb{X}}} %domain
\newcommand{\IS}{{\mathbb{S}}} %domain
\newcommand{\ID}{{\mathbb{D}}}
\newcommand{\IY}{{\mathbb{Y}}}
\newcommand{\cSm}{{\cal S}^{(m)}}
\newcommand{\cS}{{\cal S}_N}
\newcommand{\SM}{{\mathcal{P}}}
\newcommand{\SN}{{\mathcal{Q}}}
\newcommand{\SB}{{\mathcal{B}}}
\newcommand{\SD}{{\mathcal{D}}}

\newcommand{\iin}{\frac{i}{n}}
\newcommand{\jjn}{\frac{j}{n}}
\newcommand{\sumi}{\dsum_{i=1}^{n}}
\newcommand{\sumN}{\dsum_{i=1}^{N}}
\newcommand{\sumT}{\dsum_{t=1}^{T}}
\newcommand{\sumj}{\dsum_{j=1}^{n}}
\newcommand{\sumij}{\dsum_{i<j}}
\newcommand{\Xt}{{X_{t}}}
\newcommand{\Yt}{{Y_{t}}}
\newcommand{\la}{{\lambda}}
\newcommand{\bA}{{\bf A}}
\newcommand{\bB}{{\bf B}}
\newcommand{\bC}{{\bf C}}
\newcommand{\bAs}{{\bf A}_{\epsilon}}
\newcommand{\Bs}{B^{(\epsilon)}}
\newcommand{\bT}{{\bf T}}
\newcommand{\bu}{{\bf u}}
\newcommand{\bb}{{\bf b}}
\newcommand{\cT}{{\cal T}}
\newcommand{\cW}{{\cal W}}
\newcommand{\cC}{{\cal C}_{\epsilon}}
\newcommand{\cD}{{\mathcal{D}}}
\newcommand{\dx}{\Delta x}
\newcommand{\dt}{\Delta t}
\newcommand{\ep}{\epsilon}
\newcommand{\pC}{\partial C}

\makenomenclature
\renewcommand{\nomname}{List of Symbols}
%\renewcommand{\nompreamble}{The next list describes several symbols that will be later used within the body of the document}

\newenvironment{definition}[2][Definition]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}\hskip \labelsep {\bfseries #2.}]}{\end{trivlist}}
\newenvironment{theorem}[2][Theorem]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}\hskip \labelsep {\bfseries #2.}]}{\end{trivlist}}
\newenvironment{lemma}[2][Lemma]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}\hskip \labelsep {\bfseries #2.}]}{\end{trivlist}}
\newenvironment{exercise}[2][Exercise]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}\hskip \labelsep {\bfseries #2.}]}{\end{trivlist}}
\newenvironment{reflection}[2][Reflection]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}\hskip \labelsep {\bfseries #2.}]}{\end{trivlist}}
\newenvironment{proposition}[2][Proposition]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}\hskip \labelsep {\bfseries #2.}]}{\end{trivlist}}
\newenvironment{corollary}[2][Corollary]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}\hskip \labelsep {\bfseries #2.}]}{\end{trivlist}}

\DeclareMathOperator*{\argminA}{arg\,min} % Jan Hlavacek
\DeclareMathOperator*{\argminB}{argmin}   % Jan Hlavacek
\DeclareMathOperator*{\argminC}{\arg\min}   % rbp


% Latin text highlight
\def\latin#1{\emph{#1}}

% Mark-up commands
\def\Red#1{\textbf{\textcolor{red}{#1}}}	% for authors
\def\Blue#1{\textbf{\textcolor{blue}{#1}}}	% for reviewers


\title{TDA - filament network classification}
%\author{Le Yin, Ephy Love}
\date{November 2019}

% path to graphics
\graphicspath{{figures/}}

\begin{document}

\maketitle

\begin{abstract}

The actin cytoskeleton plays a critical role in plant cells. The filamentous structure of actin proteins can be viewed as a network endowed with a topology. We propose a novel, automated classifier, combining topological data analysis (TDA) with a machine learning framework in order to investigate and leverage the topology of actin networks. Our classifier is non-distance-based, instead using a persistence vectorization. We attain additional power, at a relatively low computational cost, through resampling. We benchmark our classifier against several distance and non-distance based classifiers, using a synthetic dataset to measure accuracy and sensitivity. We succeed in classifying the simulated networks with very high accuracy. Finally, we demonstrate an application with real data from confocal microscopy, classifying myosin-mutant and wildtype \textit{Arabidopsis} root cells.

    %\textbf{Keywords:} 
    
    %\textbf{Running head:} 
\end{abstract}

\section{Introduction}
The actin cytoskeleton is a complex network of proteins that is present in all eukaryotic cells. In addition to its function as cellular scaffolding, the actin cytoskeleton enables several basic cellular functions including the control of cellular shape and direction of movement \cite{thomas2009actin}. These basic functions are critical to many higher order physiological processes such as cell division, expansion, mobility and motility\cite{freedman2017versatile}. 

In the actin cytoskeleton, actin filament organization is thought to be governed partially by the interaction of filaments and partially by myosin motor proteins. Actin filaments are polar structures, ploymerized by globular actin proteins. Many actin-binding proteins have potential to bind to actin filaments at various sites along the filament. These binding proteins allow actin filaments to assemble and disassemble spatiotemporally. The binding proteins give rise to a dense cross-linking where filaments develop into networks at with many filaments and binding sites. To understand certain behaviors of cells, it is of tremendous importance to understand the processes that govern actin filament network organization. A key driver of these processes may be the relationship between actin-binding proteins, individual filaments and emergent networks.


Our goal in this work is to develop a framework for the classification of actin newtworks. The images of actin networks that we are interested in are captured via confocal mcroscopy. These images are very high resolution (\textbf{TODO}: add typical resolution), but still suffer from several types of noise such as: filaments moving through the focal plain, rounding of the cell at the edges, neighboring cells poluting the image, changes in microscopic conditions/settings, and many more. Therefor, confocal microsocopy has the advantage of providing a lot of high quality data at the expense of also including many noisy data. This means that in order to automatically study these images, without interjections by researchers (eliminating potential for an introduction of unforseen bias), a tool is called for which is highly robust to these types of noise.

In the fast developing field of machine learning, topological data analysis (TDA) has become increasingly popular as a tool for noisy network and signal classification. To date, researchers have used TDA to solve many real-world problems including signal identification \cite{marchese2016topological}, materials classification \cite{hiraoka2016hierarchical,maroulas2019bayesian}, shape recognition \cite{bonis2016persistence,li2014persistence}, histologic image analysis \cite{belchi2018lung,nicolau2011topology,singh2014topological}, ecology of human mobility \cite{chen2017measuring,chen2019generalized}, and cosmology \cite{sousbie2011persistent,van2010alpha}. A review of TDA and its applications is provided in \cite{wasserman2018topological}. A sub-method of TDA, persistence homology, is a popular method used to measure differences in topological features, due to its robustness in the face of purturbation of data. Persistence homology records when homological features (connections and voids) appear and vanish within data. These patterns vary between data. All of the appearances and disappearances of homological features are summarised in persistence barcodes and/or diagrams. In this work, we encode the geometric features of filaments networks into persistence diagrams and show a method of classification on the vectorization of the persistence space (a persistence space is not itself a vector space, so it has no mean for instance \textbf{TODO:cite}). We compare this approach to a traditional, distance-based classififications which attempts to summarize the similarities of the actin network topologies in the persistence space.

We are aided in our investigation of classification methods by a high quality dataset of simulated actin networks, which we use to benchmark each method. We are provided the outputs of simulations which combine theoretical physical properties with experimental stochastic simulation in order to emualte actin network dyanmics. With this methodology one can control the known factors, which will affect the structure of networks. Varying these initial conditions enables researchers to compare the conditional difference in outcomes of the simulated networks. This experimental strategy can provide an opportunity to independently examine the role each factor plays in the process. These factors could include the cross-linker density(number of cross-linkers per certain area), cross-linker stiffness, maximum angle that can exist between two filament segments to be crosslinked, and so on\cite{freedman2017versatile,freedman2018nonequilibrium}. This control mechanism also allows us to test our methods on a highly controlled and clean dataset, in order to test sensitivity and to compare between methods.

After testing several methods of actin network classification on the simulated data, we choose the top performing method and addapt it to the microscopy images. We perform a classification between myosin-mutant and wildtype \textit{Arabidopsis} root cells.


Move to discussion?:
\textbf{In this work, we propose a machine learning approach to classify filament networks generated with varied cross-linker density. Our method leverages the topology of the actin networks through Topological Data Analysis(TDA). Our exploratory work is the first time filament networks have been studied by direct topological classification. This work could serve as a pilot for future research in actin cytoskeleton organization. In the future, this work should be useful in the course of research on cytoplasmic streaming to be able to classify real cells based on images of their actin networks. This could provide biologists a method of disentangling the interaction of myosin motor proteins, the actin network, and streaming, i.e. by imaging the actin structure and clustering cells based on their actin network topology, the researcher may be able to fix a network structure while varying parameters specific to myosin.
}


The structure of this work is as follows: In section 2, we describe the data and introduce the background of persistence homology. Section 3 demonstrates two algorithms for classifying filament networks. Section 4 exhibits the numerical results. Section 5 will give conclusions and a discussion of future directions.


\section{Persistence Homology and Filament Networks}
To quantify the differences in filament networks, we need to tranform our data in a manner that reveals its hidden geometric features. We perform this transform with simplicial complexes in a manner typical of persistence homology. We use the 2-dimensional coordinates of sampled points along the filaments as initial nodes. Simplcial complexes provide a bridge between the data space and a topological space in which computation of distances between sets of data points can be realized. A simplicial complex is a finite collection of simplices of different dimensions such that faces of simplices are also simplices, and intersections of the simplices are either empty or a face of both \cite{edelsbrunner2010computational}. In particular, higher dimensional simplices are constructed from lower dimensional simplices. Vertices are 0-dim simplices. A 1-dim simplex is called an edge and is created by its two vertices as faces (note that a higher dimensional edge is constructed from lower dimensional points). A 2-dim simplex or a triangle has three edges as faces. Further more, a 3-dim simplex or a tetrahedron has four triangles as faces, another nesting of several lower dimensional features to build one of higher dimension.


\subsection{Data}

\textbf{Microscopy data:}
Microscopy data were provided in the form of one grayscale image per cell. The actin filaments fluoresce and so the intensity of each pixel of an image can be thought of as indicating the likely presense of a filament in that region of the image. In order to study the homology of an actin network, we must perform a topological tranformation on the data. Since the images contain hundreds of thousands of pixels, we chose to sample from the images a set of points, where the probability of choosing a pixel is propotionate to the pixel's intensity. We can make a choice of a number of points that we think is likely to sufficiently summarize a network. We can now perform our topological transformation on these new point clouds.


\textbf{Simulated data:}
Our synthetic data come from simulations with varried numbers of crosslinking protiens. As discussed, actin filaments are thought to be organized by cross-linking on actin-binding proteins. Filaments and inter-filament structure can then be simulated by a physical model \cite{freedman2017versatile,freedman2018nonequilibrium}. The change of initial conditions in a eukaryotic cell will cause variation in later measurement of filament networks. Our network data is simulated by three different cross-linker densities. Higher cross-linker density means more opportunities for filaments to be cross-linked, i.e. the binding and unbinding processes can be more active. As shown in Fig. \ref{fig:rawdata}(a), three kinds of filaments networks were simulated with different numbers of cross-linkers:  $825$, $1650$ and $3300$. All simulated cells were bound by a $\SI{20}{\micro\metre} \times \SI{20}{\micro\metre}$ square. Therefore, the cross-linker density of each network is $2.06$, $4.13$ and $8.25$ per $\SI{}{\micro\metre}^2$, respectively. In each network, there are a total of $100$ filaments with average length $\SI{10}{\micro\metre}$, where filaments are model as polar warm-like chain in red and blue dots represent barbed ends of these filaments. We also record the locations of the actin beads that make up the filaments, which are shown as small black circles in Fig. \ref{fig:rawdata}(b). Each actin bead is of radius $\SI{0.5}{\micro\metre}$. Our interest is in developing an automated method to accurately classify cross-linker density of filament networks from simulated network data. The actin beads of the simulated networks will act as our point clouds in the topological transormations of these synthetic data.

\begin{figure}[tbp]
	\begin{center}
		\includegraphics[width=1\textwidth]{rawdata.png}
	\end{center}
	\caption{Filament networks. Panel (a) shows three filament networks generated by $825$, $1650$ and $3300$ cross-linkers, respectively, in a $\SI{20}{\micro\metre} \times \SI{20}{\micro\metre}$ area. Each network contains $100$ filaments which are represented as red lines. The blue dots are the barbed ends of these filaments. Panel (b) shows the locations of the actin beads that make up the filaments exhibited in Panel (a).}
	\label{fig:rawdata}
\end{figure}

\subsection{Persistence Homology}
In order to build simplicial complexes, we adopt the procedure of forming Vietoris-Rips complexes on each dataset (actin network) by introducing a sequence of $\epsilon$-balls with increasing radius $\epsilon$ centered at each data point (a sampled pixel for image data or an actin bead in the synthetic data). Simplicial complexes are constructed based on intersections of these $\epsilon$-balls and each value of $\epsilon$ corresponds to an unordered group of homological features, which is called a homology group. Considering values of $\epsilon$ as a timeline, we only record when a homological feature appears and disappears. These indexes are called the birth times and death times of a particular homological feature. Moreover, the lifespan (death minus birth) of a homological feature is referred to as the feature's persistence. A set of homological features gives rise to a set of persistence measures. At the end of this procedure, when radius $\epsilon$ is sufficient larger so that the homology group remains unchanged even by further increase the radius, information of a filament network's persistence homology (the set of persistpent homology measurements) is summarized in a persistence diagram.

Figure \ref{fig:persistencediagram} depicts the process of discovering and summarizing the persistence homology of a simplified filament network. When $\epsilon=0$, the sampled points of the filament network are each their own connected component. As the $\epsilon$-spheres grow, connecetd components begin to merge. In the first column of te figure, when $\epsilon=0.3$, several of the sampled points have already connected. We denote the points which have died (having merged into a larger connected component), by ending their bar in the presistence barcode below, and plotting a point at 0 on the x-axis and at their precise time of death on the y-axis in the persistence diagram below that. When $\epsilon\approx1$, two holes form. The holes are evident in the top row, second column, of the figure, where one can see one larger and one smaller hole. We begin plotting bars for the holes in the corresponding persistence barcode below. Note that there are not yet reccords of the holes in the persistence diagram, because we require the death time of the holes in order to plot them in the 2-dimensional diagram. 

In the third column of Figure \ref{fig:persistencediagram}, when $\epsilon=1.1$, the smaller hole has closed, and become part of a larger connected component. Now a single point is plotted in the persistence diagram below and the bar is terminated.

As the algorithm progresses, the larger hole eventually dies and its corresponding bar in the persistence barcode is terminated. A point is added at the corresponding birth and death in the persistence diagram (a seconf red triangle appears in the final column). The algorithm could continue to $\epsilon=\inf$, but it is evident in this example that no more homologic information will be discovered as the spheres continue to grow. We choose to arbitrarily terminate the algorithm at $\epsilon=2$, terminate the final bar in the final barcode, and plot at (0,2) in the persistence diagram to denote final death time.

Overall, persistence homology indirectly summarizes the hidden shape of the data and transcribes this shape to the persistence diagram. With the persistent homology of each point cloud, a classifier can be generated either from the distance \cite{marchese2018signal} between persistence diagrams or by alternative vectorizations of the diagrams \cite{adams2017persistence,bubenik2015statistical,maroulas2018stable}.

\begin{figure}[!htbp]
	\begin{center}
		\includegraphics[width=1\textwidth]{figures/filaments_demo.png}
	\end{center}
	\caption{Demonstration fillament network. This network contains 3 filaments. Points are sampled along the filaments, in order to produce a point cloud from which persistence homology can be studied.}
	\label{fig:demoNetwork}
\end{figure}

\begin{figure}[!htbp]
	\begin{center}
		\includegraphics[width=1\textwidth]{figures/filaments_rips.png}
	\end{center}
	\caption{Investigation of the persistence homology of the demonstration filament network in Figure \ref{fig:demoNetwork}. The first row of figures, showes the growing $\epsilon$-spheres about the sampled points of the fillaments. The second row shows the corresponding persistence barcode. The third row shows the corresponding persistence diagram. The columns progress with the algorithm, right-to-left.}
	\label{fig:persistencediagram}
\end{figure}

\section{Filament network classifier}
Once we have persistence diagrams corresponding to the point clouds of actin networks, we are ready to classify these networks. In this work, we propose two methodologies as candidates for a filament network classifier, one is distance-based method while the other one is based on a vectorization.

\subsection{Distance-based network classifier}
Given any two persistence diagrams, we need a way to quantify the difference between them in the space of persistence diagrams. In TDA, two methods are commonly used to calculate the distance between persistence diagrams: the Bottleneck and Wasserstein distances \cite{adams2017persistence,bubenik2015statistical,edelsbrunner2010computational,kerber2017geometry,wasserman2018topological}. These distances calculate the optimal (minimal) cost in matching the points between two persistence diagrams. They assume infinitely many points of infinite multiplicity on the diagonal (where birth equals death), so that off-carnality points are matched to a point in this artificial set. In addition to the Wasserstein and Bottleneck distances, in this work we adopt a new distance, called $d^c_p$ distance, which is proposed in \cite{marchese2018signal} and has been proved to be stable in \cite{maroulas2018stable}. The cardinality of a persistence diagram may carry important information in applications, especially for those homological features which die very quickly and may be considered as insignificant in Wasserstain distance. However, the $d^c_p$ distance accounts uneven cardinalities between persistence diagrams by assigning a regularization term with the parameter $c$ rather than connecting extra points to the diagonal as is done in the Wasserstein distance. This method allows one to adjust the weight assigned to data that might be considered "topological noise" to fit the particular use case.

\begin{definition}{1}
Let $D_X$ and $D_Y$ be two persistence diagrams with cardinalities $n$ and $m$ respectively such that $n \leq m$ and denote $D_x=\{ x_1,...,x_n \}$, $D_y=\{ y_1,...,y_m \}$. Let $c>0$ and $1\leq p <\infty$ be fixed parameters. The $d^c_p$ distance between two persistence diagrams $D_x$ and $D_y$ is
\begin{align}
    d^c_p(D_x,D_y)= \left( \frac{1}{m} \left( \min_{\pi \in \Pi_m} \sum^n_{l=1} min(c,||x_l-y_{\pi(l)}||_\infty)^p+c^P|m-n|  \right) \right)^{\frac{1}{p}},
    \label{eq:dpcdistance}
\end{align}
where $\Pi_m$ is the set of permutations of $(1,...,m)$. If $m<n$, define $d^c_p(D_x,D_y):=d^c_p(D_y,D_x)$.
\end{definition}

The $d^c_p$ distance not only calculates the distance of points in two persistence diagrams without the simulated points on the diagonal, it also adds a penalty term on the difference in cardinalities of the two sets of points. The parameter $c$ in eq. (\ref{eq:dpcdistance}) is a constant that controls the weight of penalization to be added in the $d^c_p$ distance. Larger values of $c$ will yield a larger penalization. The parameter $p$ is typically chosen as $2$ since this corresponds to the Euclidean distance. We tend to evaluate $c$ between $0$ and $1$ as these have been empirically found to be appropriate options in real-world applications \cite{maroulas2018stable}.

Since persistence diagrams can summarize the homological features of multiple dimensions in one diagram, such as in the last panel of Fig. \ref{fig:persistencediagram}, the persistence diagram contains both $0$-dim features(connected components) with cardinality $5$ and $1$-dim features(holes) with cardinality $1$. We can further define the $d^c_p$ distance of a certain dimensional feature between a persistence diagram and a group of persistence diagrams.

\begin{definition}{2}
Denote $\D$ as a collection of persistence diagrams in the same class. For a specific $\beta$-dim homological feature, $\beta=0,1,2,...$, the $d^c_p$ distance between a persistence diagram $D_x$ and the set of persistence diagrams $\D$ is
\begin{align}
    d_\beta (D_x,\D)=\frac{1}{|\D|}\sum_{D \in \D} d^c_p(D_x,D),
    \label{dpcsets}
\end{align}
where $|\D|$ represents the size of class $\D$.
\end{definition}

With all preparations above complete, we can build the $d^c_p$-based network classifier. For $K$ classes of filament networks, every network in a class is generated under a unique set of constraints. Therefore, we have $K$ sets of persistence diagrams, where each set corresponds to a class of network generated under unique constraints. Given a new filament network with its persistence diagram $D'$, our goal is to classify under which constraints the network was most likely generated, i.e. to which class $k$ it most likely belongs. We can estimate this membership by calculating the distance between $D'$ and each class of persistence diagrams. We then assign the new network to the class with the smallest distance. Additionally, we parameterize the relative weights for different dimensions of homological features in the calculation of the distance and force the weights' sum to $1$. The classifier is summarized in Algorithm \ref{alg:dpcclassifier}.

\begin{algorithm}[!htbp]
	Let $B$ is highest dimension of homological features under consideration.\\ 1. Take the training set $T_1, T_2,..., T_K$ from each class of diagrams $\D_1,\D_2,...,\D_K$, \\
	2. For a new network with its corresponding persistence diagram $D'$, compute
	\begin{align}
	    d(D',T_k)=\sum^B_{\beta=0} w_\beta d_\beta (D',T_k),
	\end{align}
	\ \ \  where $\sum^B_{\beta=0}w_\beta=1$, and $w_\beta$ determine how much $\beta$-dim homological feature is considered,\\
	3. Assign $D'$ a class label $c'$ such that,
	\begin{align}
	    c'=\argminA_{1\leq k \leq K} d(D',T_k),
	\end{align}
	\caption{$d^c_p$-based network classifier}
	\label{alg:dpcclassifier}
\end{algorithm}

\subsection{Non-distance-based network classifier}

\subsubsection{Sub-sampling approach}
In our method, rather than work on the coordinates of the actin beads directly, we took several pre-processing steps in order to extract more information from the provided network samples. The actin bead data included both spatial coordinates as well as an index indicating the filament sampled. That is, for our networks $\{X_1, X_2... X_{150}\}$, we had 100 filaments in each network $\{F_1, F_2... F_{100}\}$ and therefor our sampled points have features $x, y$, and $f$, where  $x$ and $y$ are the coordinates in the plane and $f$ is the index in the identity map of $F$. 

Using Râ€™s spatial package, each filament was constructed by connecting the ($x$,$y$) bead-coordinates in each filament. A single filament network was then constructed as a multiline object from the corresponding collection of lines formed from the bead-coordinates. These multiline objects were then projected onto square grids of $200\times200$ cells. Then, for each network we sampled the multiline object into a grid with the identity function (i.e. the grid cells have value 0 unless a line and grid cell intersect then the value of the grid cell goes to 1). We now had a grid of 4000 cell values taking $\{0,1\}$. We filtered these 4000 values to only those of value 1 and used the corresponding planar coordinates to build our new simplicial complexes and persistence diagrams. All re-sampling steps are summarized in Algorithm \ref{alg:resample}. 

\begin{algorithm}[!htbp]
	Let $X_i \in \{X_1...X_{150}\}$ the set of simulated actin networks. \\
    Let $a \in \{A_{i,(x,y,f)}...A_{i,(x,y,f)}\}$ the set of points in $X_i$. $a$ is a pair, $(i, (x,y,f))$, where $i$ is an index to $X_i$, $x$ and $y$ are planar coordinates and $f$ is an index to a filament of $X_i$, $F_{i,f} \in \{F_{i,1}...F_{i,100}\}$, along which $a$ lies. See Panel A of Fig. \ref{fig:resample_algorithm} for a graphical depiction of one $X_i$. For simplicity, we will describe how our algorithm is applied to $X_1$:\\\\
	1. Reconstruct the paths of each $F_{1,f}$ by connecting $A_{1,(x,y,f)}$. See Panel B, Fig. \ref{fig:resample_algorithm}.\\
	2. We project $F_1$ onto a 200x200 square lattice with the same bounds as the given by the data. The cells, $c_{x,y}$ of the lattice take values $\{0,1\}$, where $c_{x,y}=1$ if it is intersected by one of $F_1$ and 0 otherwise. See Panel C of Fig. \ref{fig:resample_algorithm}.\\
	3. Retain only $c_{x,y}$ where $c_{x,y}=1$.\\
	4. Draw 1000 random $c_{x,y}$ without replacement and call these the elements of $R_{1, r}$. Repeat this twice so that $r$ indexes three new samples drawn from $X_1$. The three colors in Panel D of Fig. \ref{fig:resample_algorithm} denote the index $r$.\\
	5. Generate three separate persistence diagrams, $D_{1,r}$, for the new samples $R_{1,r}$. Shown in Panel E of Fig. \ref{fig:resample_algorithm}.
	\caption{Re-sampling Algorithm}
	\label{alg:resample}
\end{algorithm}

Due to the exponential growth of the computation of the Vietoris-Rips complex, rather than computing a Vietoris-Rips complex per network, $1000$ points were randomly sampled from each network $3$ times without replacement. This gives us $3$ sets of $1000$ points per network. This increased the sample size from $150$ to $450$ networks. We computed persistence diagrams for these $450$ networks and could used these to construct a classifier using the same procedure as outlined in Algorithm \ref{alg:dpcclassifier}.

\begin{figure}[tbp]
	\begin{center}
		\includegraphics[width=1\textwidth]{figures/resample_algo.png}
	\end{center}
	\caption{Example of one filament construction (B) from the supplied point cloud (A), rasterization (C), re-sampling (D), construction of persistence diagram (E) and vectorization of persistence diagram (F). The point cloud in (A) was supplied with an index that allowed for the constrution of the filaments in (B); note the coloring. This was projected onto a 200x200 raster (C). The raster was sampled into 3 sets (colored) of 1000 points (D) without replacement and the x,y coordinates are used to generate a VR complex. The persistence diagrams and vectorizations in (E) and (F) are colored the same as (D), to show the variability that arises in the vectorized persistence diagram features when this approach is taken.}
	\label{fig:resample_algorithm}
\end{figure}


\subsubsection{Persistence vectorization/classification}

In addition to distance based classification, a classification was performed on vectorized features of the persistence diagrams. A matrix was generated from the persistence diagrams which had row entries for each diagram and column features with the mean and standard error of persistence diagrams considering only the $0^{th}$ or $1^{th}$ persistence features alone and all topological features. That is, for each filament network, there is one persistence diagram which corresponds to one row of the vectorized matrix with mean and standard error of birth or death times for $0^{th}$, $1^{th}$, or all features. This gives us 12 columnar features. However, the mean and standard error of births for $0^{th}$ features are constant 0 and are not considered. Therefor, we are left with 10 entries per vector. The vectorization procedure is shown in Algorithm \ref{alg:vectorization}. 

\begin{algorithm}[!htbp]
	We vectorize $D_{1,r}$ from Algorithm 2 by taking the mean $birth$ and mean $death$ of connected components and holes. These data are plotted in Panel F of Figure 3. For $D_{1,r}$ we have 3 row-vectors in the form:
	\begin{center}
	    $v_{1,r}$ =
        $\begin{bmatrix}
            \bar{x}(\mathrm{Death~of~Connected~components})\\
            s(\mathrm{Death~of~Connected~components})\\
            \bar{x}(\mathrm{Birth~of~holes})\\
            s(\mathrm{Birth~of~holes})\\
            \bar{x}(\mathrm{Death~of~holes})\\
            s(\mathrm{Death~of~holes})\\
            \bar{x}(\mathrm{Birth~of~all~features})\\
            s(\mathrm{Birth~of~all~features})\\
            \bar{x}(\mathrm{Death~of~all~features})\\
            s(\mathrm{Death~of~all~features})\\
        \end{bmatrix}$
    \end{center}
	Note: the mean $\bar{x}$ and standard error $s$ of the birth of connected components would be $0$ for all vectors, so these are not found in $v_{1,r}$. Repeat for all $X_i$. Our complete matrix of data has a final dimension $450\times10$.\\
	\caption{Vectorization of persistence diagrams}
	\label{alg:vectorization}
\end{algorithm}

\section{Classification result}

\subsection{$d^c_p$-based classifier}
In our data set, we are provided three classes of filament networks. Each class of filament network is generated with a different number of cross-linking proteins. Each class contains $50$ samples. Therefore, there are total of $150$ individual provided filament networks. 

In order to compare classifiers, we employed $10$-fold cross validation to estimate overall classification accuracy. All of the networks are randomly partitioned into $10$ mutually exclusive sets. $9$ partitions are selected as a training set, while the remaining $1$ partition is used for testing. We repeat the classification $10$ times such that every partition acts as a testing set exactly once. We consider the overall classification accuracy rate as the mean accuracy across all partitions.

After generating the persistence diagram for each filament network from the locations of actin beads, we tested our classifier on this data set using the $d^c_p$-based classifier in Algorithm~\ref{alg:dpcclassifier}. We consider only $0$-dim and $1$-dim topological homological features. We chose $p=2$ to imitate Euclidean distance. The choices of parameter $w_0, w_1, c$ were found to be optimal based on cross validation. When $w_0=0.5, w_1=0.5$, connected components and holes are weighted equally, and $c=0.2$ gives a relatively small contribution from the cardinality difference in the $d^c_p$ distances, the best classification accuracy rate is $89\%$.

\subsection{non-distence based}

A support vector machine (SVM) was used to develop a network classifier based on the 3-times re-sampled and vectorized persistence diagrams. $10$-fold cross-validation was again used to assess the accuracy of the SVM classifier. Accuracy was measured only on one of the three sub-sampled networks $R_{i,1}$ per filament network $X_i$ so as to fairly compare to the methods without re-sampling. The mean accuracy of the classifier was 96.3\%. This was the highest accuracy attained on this set of simulated networks.

\subsection{Comparison to other classifiers}
We also list the accuracy rate by using other classifier in Table \ref{tab:accuracyrate}.
\begin{table}[!htb]
	\begin{center}
		\begin{tabular}{c|c}
			\hline
			\textbf{classifier} & \textbf{accuracy} \\
			\hline
			SVM, re-sampled & 96\%  \\
			\hline
			$d^c_p$-based & 89\%  \\
			\hline
			Wasserstein-based, re-sampled & 87\%  \\
			\hline
			Wasserstein-based & 83\%  \\
			\hline
			Bayes Factor \cite{maroulas2019bayesian} & 83\%  \\
			\hline
			SVM PI \cite{adams2017persistence} & 75\%  \\
			\hline
			Neural Net PI & 71\%  \\
			\hline
			SVM Raster & 65\%  \\
			\hline
			Random Forest Raster & 55\%  \\
			\hline
		\end{tabular}
		\caption{Accuracy rate of classifiers}\label{tab:accuracyrate}
	\end{center}
\end{table}

Our findings show that re-sampling of data can produce a more reliable filament network classifier even when data are mapped to a topological space and summarized in persistence diagrams. The $d^c_p$-based classifier performed much better than Wasserstein-based classifier. Our re-sampled and vectorized persistence diagram based classifier and $d^c_p$-based classifier are superior than any other common classifiers. These findings suggest that future with with real data microscopy data may be classified with similar methods.

\subsection{Application to classifying myosin mutants}
We are given labeled images of cells belonging to one of two classes: myosin mutant (MM) or wild type (WT). The MM cells have a genetic knockout such that they do not a produce one of their myosin proteins. The WT cells are the control with no knockout. Myosin motor proteins are known, via empirical observation, to influence the connectivity and shape of the actin filament network. This experiment differs from our synthetic experiment in that our synthetic experiment involved the direct manipulation of the actin network through changes in cross-linker abundance. Whereas cross-linking is fundamental to the structure of the actin network, the linkage betweeen mysoin motors and actin networks is more complex and likely modulated by several interacting factors.

\begin{figure}[H]
	\begin{center}
		\includegraphics[width=.9\textwidth]{figures/wtCell.png}
	\end{center}
	\caption{Example of a raw WT cell image.}
	\label{fig:wtCell}
\end{figure}

We perform classification of MMs and WTs using our top classifier, the re-sampled SVM. The data are provided as tifs from 22 MM and 20 WT cells. Each tif is a a very high resolution (roughly 2500x500 pixels with 0.043 $\mathrm{\mu m}^2$ pixels) grayscale image, wherein the pixel values are an 8-bit inensity. We perform preprocessing on the images simply by performing a gaussian blur and then thresholding to the top $\frac{1}{3}$ of values. The thresholded image is then a grid of values taking only 0 or 1, where 1 indicates the presense of a filament. We then take the processed images and proceed in classification from step (C) in Figure \ref{fig:resample_algorithm}, resampling, computing PDs, vecorizing the PDs, and finally classifying with an SVM. We find a cross-validated (k=5) accuracy of roughly 73\%.

Interpretation of these results is complicated by our uncertainty of the true, cumulative impact of the moyin knockout on the actin network. While the accuracy in this experiment is significantly lower than found in the analysis of the synthetic data, this could easily be explained by the single motor protein knockout having a relatively minor impact on actin organization when compared with up or down regualtion of cross-linkers. Out of curiosity, we conducted a small survey (\textit{n}=6), wherein we asked respondents who were familiar with the experiment to sepparate the cells into two classes. We found that respondents had an average accuracy of 63\%, with a minimum accuracy of random chance and a maximum accuracy of 75\%. Since our algorithm is (on average) more effective than manual classification by an expert, we conclude that there is likely a weak relationship between this mysoin knockout and actin network structure, and our classification algorithm is likely running into the ceiling of discernible difference in classes.


\section{Conclusion}
In this work, we successfully classified simulated actin filament networks, generated under three different initial conditions, with very high accuracy. We combined a machine learning framework with TDA for our classification. We compared with several distance-based classifiers. Our method most successful method uses a resampling technique, a vectorization of the persistence diagram and an SVM as the classifier. Each of these methods were built on the foundation of topological homology by encoding geometric features hidden in the data into the topological features and summarizing those into persistence diagrams.

From these results, we are able to confidently classify synthetic actin filament networks based on unique inital conditions. Accordingly, these methods could reveal key factors in the filament network organizing process and provide biologists with opportunities to study the interaction of motor proteins, actin networks and cytoplasmic streaming. We demonstrate that it is simple to bridge our method to classify cells by microscopy images of their actin networks. Overall, our work is the first time that actin filament networks have been studied by direct topological classification. Researchers could further advance their understanding of cell physiology through this work and future research. 

\clearpage	
%\nocite{*}
\bibliographystyle{plain}
\bibliography{bibliography}


\end{document}
